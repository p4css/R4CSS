---
title: "R05_6_TM_President_Speech"
output:
  html_document:
    theme: cerulean
    highlight: zenburn
    toc: yes
    toc_float:
      collapsed: no
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
options(stringsAsFactors = F)
options(verbose = T)
options(scipen = 999)
library(tidytext)
library(jiebaR)
library(lubridate)
```


# Loading data
```{r}
fnames <- list.files("data/president_speech/", full.names = T)
contents <- c()
for(fn in fnames){
    contents <- c(contents, read_file(fn))
}

raw.df <- tibble(fname = fnames, content = contents) %>%
    mutate(fname = str_replace(fname, ".*_speech//([0-9]+)", "\\1"),
           fname = str_c("p", str_pad(fname, 2, pad="0"))) %>%
    mutate(content = str_replace_all(content, "台灣", "臺灣"))
```



# Tokenization
## Initializing jieba
```{r}
segment_not <- c("蔡英文", "馬英九")
cutter <- worker()
new_user_word(cutter, segment_not)
stopWords <- readRDS("data/stopWords.rds")
watched <- c("青年")
```


## Tokenized to unnested tidy form
```{r}
unnested.df <- raw.df %>% 
    mutate(word = map(content, function(x)segment(x, cutter))) %>%
    unnest(word) %>%
    filter(!str_detect(word, "[a-zA-Z0-9]+") | (word %in% watched)) %>%
    filter(!(word %in% setdiff(stopWords, watched))) %>%
    filter(nchar(word) > 1 | (word %in% watched)) %>%
    select(doc = fname, word)
```


# Visualization

## Visualizing specific terms of 2020 by log-ratio compared with 2016
```{r}

```



# Topic modeling
## Convert to doc-term-matrix
```{r}

```

## Topic modeling
```{r}
# install.packages("topicmodels")
library(topicmodels)

```


# Inspecting topic modeling results
## topic-term prabability: beta

```{r}

```


## Evaluation LDA by perplexity
```{r}

```

## Document-topic probability: gamma
```{r}

```
